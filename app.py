import streamlit as st
import json
import os
import io
import csv # CSVå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import time # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã®å¾…æ©Ÿç”¨
from pydantic import BaseModel, Field, ValidationError, ConfigDict # ConfigDictã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from typing import Optional, Literal, Dict, Any, List, Union # Unionã‚’è¿½åŠ 
import re # æ­£è¦è¡¨ç¾ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿½åŠ 

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import pypdf # PDFå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import docx # DOCXå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (python-docx)
import openpyxl # XLSXå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from pptx import Presentation # PPTXå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (python-pptx)

# ----------------------------------------------------------------------
# âš ï¸ æ³¨æ„: Gemini APIä¾å­˜ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã€Google Geminiã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ä½¿ç”¨ã—ã¾ã›ã‚“ã€‚
# ----------------------------------------------------------------------

# ----------------------------------------------------------------------
# 1. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å®šç¾© (Pydanticã§ç¶™ç¶š)
# ----------------------------------------------------------------------

# è«–æ–‡ãƒ‡ãƒ¼ã‚¿
class PaperData(BaseModel):
    year: str = Field(description="å‡ºç‰ˆå¹´è¥¿æš¦ (ä¾‹: 2024)")
    author: str = Field(description="ä¸»è¦è‘—è€…åã€‚ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")
    title: str = Field(description="è«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã€‚")

# è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸ãƒ‡ãƒ¼ã‚¿
class InvoiceData(BaseModel):
    invoice_date: str = Field(description="ç™ºè¡Œæ—¥ã€‚YYYY-MM-DDå½¢å¼ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚")
    invoice_amount: str = Field(description="åˆè¨ˆé‡‘é¡ã€‚æ•°å­—ã¨é€šè²¨è¨˜å·ã‚’å«ã‚“ã å…ƒã®æ–‡å­—åˆ—ã€‚")
    invoice_issuer: str = Field(description="ç™ºè¡Œå…ƒ/ç™ºè¡Œè€…åã€‚")
    invoice_subject: str = Field(description="è«‹æ±‚æ›¸/é ˜åæ›¸ã®ä»¶åã€‚")

# ãã®ä»–ãƒ‡ãƒ¼ã‚¿
class OtherData(BaseModel):
    title: str = Field(description="ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’æœ€ã‚‚ã‚ˆãè¡¨ã™ã€AIãŒæ¨æ¸¬ã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã€‚")

# AIã‚³ã‚¢ã‹ã‚‰ã®æœ€çµ‚å¿œç­”ã‚¹ã‚­ãƒ¼ãƒ
Category = Literal["è«–æ–‡", "è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸", "ãã®ä»–", "ä¸æ˜"]

class AICoreResponse(BaseModel):
    # ä½™åˆ†ãªå…¥åŠ›ã‚’ç„¡è¦–ã™ã‚‹è¨­å®š
    model_config = ConfigDict(extra='ignore')

    category: Category = Field(description="ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†é¡ã‚«ãƒ†ã‚´ãƒªã€‚å¿…é ˆã€‚å–ã‚Šã†ã‚‹å€¤: è«–æ–‡, è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸, ãã®ä»–, ä¸æ˜")
    extracted_data: Optional[Union[PaperData, InvoiceData, OtherData, Dict[str, Any]]] = Field( 
        None, 
        description="åˆ†é¡ã«å¿œã˜ãŸæŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚ä¸æ˜ã®å ´åˆã¯ null ã«ã—ã¦ãã ã•ã„ã€‚"
    )
    reasoning: str = Field(description="ãã®åˆ†é¡ã¨æŠ½å‡ºã‚’è¡Œã£ãŸæ ¹æ‹ ã€‚")
    transcript: Optional[str] = Field(None, description="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥åŠ›ã•ã‚ŒãŸå ´åˆã®æ–‡å­—èµ·ã“ã—çµæœã€‚")

# ----------------------------------------------------------------------
# 2. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å‡¦ç†æ©Ÿèƒ½ (ãƒ•ã‚¡ã‚¤ãƒ«æŠ½å‡ºã¨ãƒ­ãƒ¼ã‚«ãƒ«AIé€£æº)
# ----------------------------------------------------------------------

# --- (extract_text é–¢æ•°ã¯å¤‰æ›´ãªã—) ---
def extract_text(uploaded_file: st.runtime.uploaded_file_manager.UploadedFile) -> tuple[str, bool]:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°ã€‚
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Œæ–‡å­—èµ·ã“ã—ãŒå¿…è¦ã€ã¨ã—ã¦ãƒ•ãƒ©ã‚° (is_asr=True) ã‚’è¿”ã™ã€‚
    """
    file_ext = uploaded_file.name.split('.')[-1].lower()
    
    # å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®ãƒã‚§ãƒƒã‚¯
    supported_extensions = ['pdf', 'docx', 'xlsx', 'pptx', 'csv', 'mp3', 'wav', 'm4a']
    if file_ext not in supported_extensions:
        return f"ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ '{file_ext}' ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚", False

    # --- éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† (ãƒ•ãƒ©ã‚°ã‚’è¿”ã™) ---
    if file_ext in ['mp3', 'wav', 'm4a']:
        st.info(f"ğŸ”Š éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ­ãƒ¼ã‚«ãƒ«ASRå‡¦ç†ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        # âš ï¸ Geminiã‚’ä½¿ã‚ãªã„ãŸã‚ã€ASRã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ¢ãƒƒã‚¯ã¨ã—ã¦å‡¦ç†ã™ã‚‹
        return uploaded_file.name, True 

    # --- PDF å‡¦ç† (å®‰å®šæ€§å¼·åŒ–) ---
    if file_ext == 'pdf':
        try:
            st.info(f"ğŸ“„ PDFãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            pdf_reader = pypdf.PdfReader(uploaded_file)
            text_content = ""
            for page in pdf_reader.pages:
                try:
                    text_content += page.extract_text() or ""
                except (TypeError, ValueError) as e:
                    st.warning(f"âš ï¸ ãƒšãƒ¼ã‚¸æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                    continue
                
            if not text_content.strip():
                st.warning("âš ï¸ PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒ£ãƒ³ç”»åƒã¨è¦‹ãªã—ã¦ãƒ¢ãƒƒã‚¯OCRãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                text_content = "OCRçµæœ: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯2024å¹´4æœˆ1æ—¥ã«ç™ºè¡Œã•ã‚ŒãŸé ˜åæ›¸ã§ã‚ã‚Šã€é‡‘é¡ã¯25,000å††ã§ã™ã€‚ç™ºè¡Œå…ƒã¯ABCã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°ã§ã™ã€‚"
            
            return text_content, False
        
        except Exception as e:
            st.error(f"ğŸš¨ PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"PDFå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- DOCX å‡¦ç† ---
    elif file_ext == 'docx':
        try:
            st.info(f"ğŸ“„ DOCXãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            document = docx.Document(io.BytesIO(uploaded_file.getvalue()))
            text_content = ""
            for paragraph in document.paragraphs:
                text_content += paragraph.text + '\n' 
                
            if not text_content.strip():
                st.warning("âš ï¸ DOCXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãŒç©ºã‹ã€èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
            return text_content, False

        except Exception as e:
            st.error(f"ğŸš¨ DOCXå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"DOCXå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- XLSX å‡¦ç† ---
    elif file_ext == 'xlsx':
        try:
            st.info(f"ğŸ“Š XLSXãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            workbook = openpyxl.load_workbook(uploaded_file, read_only=True)
            text_content = ""
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                text_content += f"\n--- ã‚·ãƒ¼ãƒˆ: {sheet_name} ---\n"
                
                for row in sheet.iter_rows():
                    row_data = []
                    for cell in row:
                         if cell.value is not None:
                            row_data.append(str(cell.value))
                    if row_data:
                        text_content += ', '.join(row_data) + '\n'
            
            if not text_content.strip():
                st.warning("âš ï¸ XLSXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            return text_content, False

        except Exception as e:
            st.error(f"ğŸš¨ XLSXå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"XLSXå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- PPTX å‡¦ç† (å®‰å®šæ€§å¼·åŒ–) ---
    elif file_ext == 'pptx':
        try:
            st.info(f"ğŸ–¼ï¸ PPTXãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            presentation = Presentation(uploaded_file)
            text_content = ""
            
            for i, slide in enumerate(presentation.slides):
                text_content += f"\n--- ã‚¹ãƒ©ã‚¤ãƒ‰ {i+1} ---\n"
                for shape in slide.shapes:
                    if hasattr(shape, "text_frame") and shape.text_frame: # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                        text_content += shape.text + '\n'
                    elif shape.has_table:
                        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒ«å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆã‚Šç¢ºå®Ÿã«å–å¾—
                        for row in shape.table.rows:
                            row_data = []
                            for cell in row.cells:
                                if cell.text_frame:
                                    row_data.append(cell.text)
                            text_content += ' | '.join(row_data) + '\n'
                    elif shape.has_text_frame: # has_text_frameã¯text_frameã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯
                        text_content += shape.text_frame.text + '\n'

            if not text_content.strip():
                st.warning("âš ï¸ PPTXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

            return text_content, False
        
        except Exception as e:
            st.error(f"ğŸš¨ PPTXå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"PPTXå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- CSV å‡¦ç† ---
    elif file_ext == 'csv':
        try:
            st.info(f"ğŸ“‹ CSVãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            text_stream = io.StringIO(uploaded_file.getvalue().decode('utf-8'))
            reader = csv.reader(text_stream)
            
            text_content = ""
            for row in reader:
                text_content += ', '.join(row) + '\n'

            if not text_content.strip():
                st.warning("âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã‹ã€èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

            return text_content, False

        except Exception as e:
            st.error(f"ğŸš¨ CSVå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"CSVå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False
            

# --- Gemini APIé€£æºã‚’ç½®ãæ›ãˆã‚‹ãƒ­ãƒ¼ã‚«ãƒ«åˆ†æé–¢æ•°ã«ä¿®æ­£ ---
def analyze_file_content(text_content: str, uploaded_file: st.runtime.uploaded_file_manager.UploadedFile, is_asr: bool) -> AICoreResponse:
    """
    Gemini APIã®ä»£ã‚ã‚Šã«ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’åˆ†æã—ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if is_asr:
        # âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ãƒ¢ãƒƒã‚¯ (è¦ä»¶ 4. ASR)
        transcript = "ãƒ¢ãƒƒã‚¯æ–‡å­—èµ·ã“ã—: 2023å¹´10æœˆ5æ—¥ã€ç”°ä¸­å•†äº‹ã‹ã‚‰15000å††ã®è«‹æ±‚æ›¸ã‚’å—é ˜ã—ã¾ã—ãŸã€‚ä»¶åã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚"
        
        # ãƒ¢ãƒƒã‚¯ã®æŠ½å‡ºãƒ‡ãƒ¼ã‚¿
        data = InvoiceData(
            invoice_date="2023-10-05",
            invoice_amount="15000å††",
            invoice_issuer="ç”°ä¸­å•†äº‹",
            invoice_subject="ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ©ã‚¤ã‚»ãƒ³ã‚¹"
        )
        return AICoreResponse(
            category="è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸",
            extracted_data=data,
            reasoning="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã§ã—ãŸãŒã€ãƒ­ãƒ¼ã‚«ãƒ«ASRãƒ¢ãƒƒã‚¯ã«ã‚ˆã‚Šè«‹æ±‚æƒ…å ±ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚",
            transcript=transcript
        )

    # æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹åˆ†æ (ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹)
    lower_text = text_content.lower()
    
    # 1. è«‹æ±‚æ›¸/é ˜åæ›¸ ãƒ«ãƒ¼ãƒ«
    if "è«‹æ±‚æ›¸" in lower_text or "é ˜åæ›¸" in lower_text or "invoice" in lower_text or "receipt" in lower_text:
        st.info("ğŸ” ãƒ­ãƒ¼ã‚«ãƒ«AI: è«‹æ±‚æ›¸/é ˜åæ›¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã€‚")
        
        # æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ã®ç°¡ç•¥åŒ– (æ­£è¦è¡¨ç¾ã§ä¸»è¦é …ç›®ã‚’æŠ½å‡º)
        date_match = re.search(r"(\d{4}[-/]\d{1,2}[-/]\d{1,2})", text_content)
        amount_match = re.search(r"(Â¥|ï¿¥|\$|â‚¬|Â£)?\s*[\d,]+\.?\d*", text_content)
        
        if date_match and amount_match:
            data = InvoiceData(
                invoice_date=date_match.group(1).replace('/', '-'),
                invoice_amount=amount_match.group(0),
                invoice_issuer="ä¸æ˜ãªç™ºè¡Œå…ƒ", 
                invoice_subject=uploaded_file.name 
            )
            return AICoreResponse(
                category="è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸",
                extracted_data=data,
                reasoning="ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚Šæ—¥ä»˜ã¨é‡‘é¡ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚"
            )

    # 2. è«–æ–‡ ãƒ«ãƒ¼ãƒ«
    if any(keyword in lower_text for keyword in ["abstract", "introduction", "author", "year of publication"]):
        st.info("ğŸ” ãƒ­ãƒ¼ã‚«ãƒ«AI: è«–æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã€‚")

        # æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ã®ç°¡ç•¥åŒ–
        year_match = re.search(r"(?:Year|Date|Published):?\s*(\d{4})", text_content, re.IGNORECASE)
        author_match = re.search(r"(?:Author|è‘—è€…):?\s*([A-Za-z\s.,]+)", text_content, re.IGNORECASE)

        if year_match and author_match:
            data = PaperData(
                year=year_match.group(1),
                author=author_match.group(1).strip(),
                title=uploaded_file.name # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡ºã¯å›°é›£ãªãŸã‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨
            )
            return AICoreResponse(
                category="è«–æ–‡",
                extracted_data=data,
                reasoning="ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚Šè‘—è€…ã¨ç™ºè¡Œå¹´ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚"
            )

    # 3. ãã®ä»–/ä¸æ˜
    if text_content.strip():
        # ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°ã€Œãã®ä»–ã€ã¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦ææ¡ˆ
        data = OtherData(
            title=os.path.splitext(uploaded_file.name)[0]
        )
        return AICoreResponse(
            category="ãã®ä»–",
            extracted_data=data,
            reasoning="ç‰¹å®šã®æ–‡æ›¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã—ãªã‹ã£ãŸãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…ƒã«ãƒªãƒãƒ¼ãƒ ã—ã¾ã™ã€‚"
        )
    else:
        # ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã®å ´åˆ
        return AICoreResponse(
            category="ä¸æ˜",
            extracted_data=None,
            reasoning="ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å†…å®¹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        )


def apply_rename_rule(ai_response: AICoreResponse, original_name: str) -> str:
    """
    è¦ä»¶ 6 ã«åŸºã¥ãã€AIã®å¿œç­”ã‹ã‚‰ãƒªãƒãƒ¼ãƒ å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    base_name, ext = os.path.splitext(original_name)
    category = ai_response.category
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ dict å½¢å¼ã§å–å¾—ã€‚extracted_data ãŒ None ã®å ´åˆã¯ç©ºã® dict ã‚’ä½¿ç”¨
    # ãƒ¢ãƒƒã‚¯å‡¦ç†ãªã®ã§ã€Pydanticãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç›´æ¥ dict ã«å¤‰æ› (ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚)
    data = ai_response.extracted_data.model_dump() if ai_response.extracted_data else {} 

    # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã§ããªã„æ–‡å­—ã‚’å‰Šé™¤/ç½®æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def sanitize_filename(name: str) -> str:
        safe_name = name.replace(' ', '_')
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨å¯èƒ½ãªæ–‡å­—ã®ã¿ã‚’è¨±å¯
        return ''.join(c for c in safe_name if c.isalnum() or c in '._-')

    # 4. ä¸æ˜: ãƒªãƒãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—
    if category == "ä¸æ˜":
        st.warning("âš ï¸ ã‚«ãƒ†ã‚´ãƒªãŒã€Œä¸æ˜ã€ã®ãŸã‚ã€ãƒªãƒãƒ¼ãƒ å‡¦ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")
        return original_name

    # 1. è«–æ–‡ (è¦ä»¶ 6.1)
    elif category == "è«–æ–‡":
        year = data.get("year", "YYYY")
        authors = data.get("author", "è‘—è€…åä¸æ˜")
        title = data.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")

        authors_short = authors[:15] if len(authors) > 15 else authors
        max_title_len = 50 - len(year) - len(authors_short) - 2
        title_short = title[:max(0, max_title_len)]

        new_name_raw = f"{year}_{authors_short}_{title_short}"
        return f"{sanitize_filename(new_name_raw)}{ext}"

    # 2. è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸ (è¦ä»¶ 6.2)
    elif category == "è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸":
        date_str_raw = data.get("invoice_date", "YYYYMMDD")
        # æ—¥ä»˜ã«å«ã¾ã‚Œã‚‹æ•°å­—ã ã‘ã‚’å–ã‚Šå‡ºã—ã€8æ¡ã«åˆ¶é™
        date_str = ''.join(filter(str.isdigit, date_str_raw))[:8]

        issuer = data.get("invoice_issuer", "ç™ºè¡Œå…ƒä¸æ˜")[:15]
        
        amount_raw = data.get("invoice_amount", "0")
        # é‡‘é¡ã«å«ã¾ã‚Œã‚‹æ•°å­—ã ã‘ã‚’å–ã‚Šå‡ºã—ã€ã‚«ãƒ³ãƒã‚„é€šè²¨è¨˜å·ã‚’å‰Šé™¤
        amount = ''.join(filter(str.isdigit, amount_raw)) or "0" 
        
        subject = data.get("invoice_subject", "ä»¶åãªã—")[:15]

        new_name_raw = f"{date_str}_{issuer}_{amount}_{subject}"
        return f"{sanitize_filename(new_name_raw)}{ext}"

    # 3. ãã®ä»– (è¦ä»¶ 6.3)
    elif category == "ãã®ä»–":
        title = data.get("title", "AIæ¨æ¸¬ã‚¿ã‚¤ãƒˆãƒ«")[:30]
        return f"{sanitize_filename(title)}{ext}"
    
    # äºˆæœŸã›ã¬åˆ†é¡ã‚¨ãƒ©ãƒ¼
    else:
        st.error(f"ğŸš¨ ãƒªãƒãƒ¼ãƒ ãƒ«ãƒ¼ãƒ«é©ç”¨ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ†ã‚´ãƒª '{category}' ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒä¸æ­£ã§ã™ã€‚å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿”ã—ã¾ã™ã€‚")
        return original_name

# ----------------------------------------------------------------------
# 3. Streamlit UIå®šç¾© (è¦ä»¶ 3)
# ----------------------------------------------------------------------

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ğŸ¤– AIã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (Local Mode)", layout="wide")

## ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    st.markdown("""
    **å‹•ä½œãƒ¢ãƒ¼ãƒ‰:** èª°ã§ã‚‚ä½¿ãˆã‚‹ãƒ­ãƒ¼ã‚«ãƒ«ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰
    
    *Gemini APIã‚’ä½¿ç”¨ã—ãªã„ãŸã‚ã€APIã‚­ãƒ¼ã¯ä¸è¦ã§ã™ã€‚*
    *æ–‡æ›¸åˆ†æã«ã¯Pythonã®æ­£è¦è¡¨ç¾ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚*
    *éŸ³å£°æ–‡å­—èµ·ã“ã—ã¯å›ºå®šã®ãƒ¢ãƒƒã‚¯å¿œç­”ã¨ãªã‚Šã¾ã™ã€‚*
    """)
    
    st.markdown("---")
    st.subheader("å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ (è¦ä»¶ 4)")
    st.markdown("""
    * **æ–‡æ›¸**: PDF, DOCX, XLSX, PPTX, CSV
    * **éŸ³å£°**: MP3, WAV, M4A (ãƒ¢ãƒƒã‚¯)
    """)

## ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
st.title("ğŸ¤– AIã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (Local Mode)")
st.caption("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ«ãƒ¼ãƒ«ã§åˆ†æã—ã€è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã‚’è¡Œã„ã¾ã™ã€‚")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ (è¦ä»¶ 3)
uploaded_files = st.file_uploader(
    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (è¤‡æ•°é¸æŠå¯)", 
    type=['pdf', 'docx', 'xlsx', 'pptx', 'csv', 'mp3', 'wav', 'm4a'],
    accept_multiple_files=True
)

if uploaded_files:
    if st.button("ğŸš€ ãƒ­ãƒ¼ã‚«ãƒ«ãƒªãƒãƒ¼ãƒ ãƒ»æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ", use_container_width=True):
        
        # å‡¦ç†çŠ¶æ³ã®è¡¨ç¤º (è¦ä»¶ 3)
        st.subheader("ğŸ“Š å‡¦ç†çµæœ")
        results: List[Dict[str, Any]] = []
        
        progress_bar = st.progress(0)
        
        with st.empty(): 
            for i, uploaded_file in enumerate(uploaded_files):
                
                progress_bar.progress((i + 1) / len(uploaded_files))
                st.info(f"ğŸ‘‰ **{uploaded_file.name}** ã®å‡¦ç†ã‚’é–‹å§‹...")
                
                # 1. ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º/ASRåˆ¤å®š
                text_content, is_asr = extract_text(uploaded_file)
                
                if "å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“" in text_content or "ã‚¨ãƒ©ãƒ¼" in text_content:
                    results.append({
                        "ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                        "å‡¦ç†çŠ¶æ³": "ã‚¹ã‚­ãƒƒãƒ—/ã‚¨ãƒ©ãƒ¼",
                        "åˆ†é¡ã‚«ãƒ†ã‚´ãƒª": "-",
                        "ãƒªãƒãƒ¼ãƒ å¾Œãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                    })
                    continue
                
                # 2. ãƒ­ãƒ¼ã‚«ãƒ«AIã‚³ã‚¢é€£æº
                ai_response = analyze_file_content(text_content, uploaded_file, is_asr)
                
                if ai_response.category == "ä¸æ˜":
                    st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file.name} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç†ç”±: {ai_response.reasoning}")

                # 3. ãƒªãƒãƒ¼ãƒ ãƒ«ãƒ¼ãƒ«é©ç”¨ (è¦ä»¶ 6)
                new_filename = apply_rename_rule(ai_response, uploaded_file.name)
                
                # 4. çµæœã®è¨˜éŒ²ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®è¨­ç½®
                result_data = {
                    "ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                    "å‡¦ç†çŠ¶æ³": "å®Œäº†" if ai_response.category != "ä¸æ˜" else "å¤±æ•—",
                    "åˆ†é¡ã‚«ãƒ†ã‚´ãƒª": ai_response.category,
                    "ãƒªãƒãƒ¼ãƒ å¾Œãƒ•ã‚¡ã‚¤ãƒ«å": new_filename,
                }
                results.append(result_data)
                
                st.markdown(f"**çµæœ ({uploaded_file.name})**:")
                
                col1, col2, col3 = st.columns([1, 1, 2])
                
                with col1:
                    st.download_button(
                        label=f"ğŸ’¾ {new_filename} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=uploaded_file.getvalue(), 
                        file_name=new_filename,
                        mime=uploaded_file.type,
                        key=f"download_renamed_{uploaded_file.name}"
                    )

                if is_asr and ai_response.transcript:
                    with col2:
                        asr_file_name = f"{os.path.splitext(uploaded_file.name)[0]}.txt"
                        st.download_button(
                            label=f"ğŸ“ {asr_file_name} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=ai_response.transcript,
                            file_name=asr_file_name,
                            mime="text/plain",
                            key=f"download_asr_{uploaded_file.name}"
                        )
                
                with col3:
                    st.caption(f"åˆ†é¡: **{ai_response.category}** | ç†ç”±: {ai_response.reasoning}")

            st.success("âœ… å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        st.dataframe(results, use_container_width=True)
        
        st.markdown("---")
        st.subheader("ğŸ’¡ æœ€çµ‚åˆ†æçµæœ (æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿)")
        if 'ai_response' in locals() and ai_response:
            # Pydanticãƒ¢ãƒ‡ãƒ«ã‚’è¾æ›¸ã«å¤‰æ›ã—ã¦è¡¨ç¤º
            st.json(ai_response.model_dump())
        else:
            st.write("ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‡¦ç†ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
