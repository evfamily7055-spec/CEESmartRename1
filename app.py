import streamlit as st
import json
import os
import io
import csv # CSVå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import time # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã®å¾…æ©Ÿç”¨
from pydantic import BaseModel, Field, ValidationError, ConfigDict # ConfigDictã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from typing import Optional, Literal, Dict, Any, List, Union # Unionã‚’è¿½åŠ 
import re # æ­£è¦è¡¨ç¾ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿½åŠ 

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import pypdf # PDFå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import docx # DOCXå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (python-docx)
import openpyxl # XLSXå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from pptx import Presentation # PPTXå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (python-pptx)

# ----------------------------------------------------------------------
# âš ï¸ æ³¨æ„: Gemini APIä¾å­˜ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã€Google Geminiã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ä½¿ç”¨ã—ã¾ã›ã‚“ã€‚
# ----------------------------------------------------------------------

# ----------------------------------------------------------------------
# 1. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å®šç¾© (Pydanticã§ç¶™ç¶š)
# ----------------------------------------------------------------------

# è‘—è€…ä»˜ãæ–‡æ›¸ãƒ‡ãƒ¼ã‚¿
class AuthorData(BaseModel):
    author: str = Field(description="ä¸»è¦è‘—è€…åã€‚ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")
    title: str = Field(description="æ–‡æ›¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã€‚")

# è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸ãƒ‡ãƒ¼ã‚¿
class InvoiceData(BaseModel):
    invoice_date: str = Field(description="ç™ºè¡Œæ—¥ã€‚YYYY-MM-DDå½¢å¼ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚")
    invoice_amount: str = Field(description="åˆè¨ˆé‡‘é¡ã€‚æ•°å­—ã¨é€šè²¨è¨˜å·ã‚’å«ã‚“ã å…ƒã®æ–‡å­—åˆ—ã€‚")
    invoice_issuer: str = Field(description="ç™ºè¡Œå…ƒ/ç™ºè¡Œè€…åã€‚")
    invoice_subject: str = Field(description="è«‹æ±‚æ›¸/é ˜åæ›¸ã®ä»¶åã€‚")

# ãã®ä»–ãƒ‡ãƒ¼ã‚¿
class OtherData(BaseModel):
    title: str = Field(description="ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’æœ€ã‚‚ã‚ˆãè¡¨ã™ã€AIãŒæ¨æ¸¬ã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã€‚")

# AIã‚³ã‚¢ã‹ã‚‰ã®æœ€çµ‚å¿œç­”ã‚¹ã‚­ãƒ¼ãƒ
Category = Literal["è«–æ–‡", "è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸", "ãã®ä»–", "ä¸æ˜"]

class AICoreResponse(BaseModel):
    model_config = ConfigDict(extra='ignore')

    category: Category = Field(description="ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†é¡ã‚«ãƒ†ã‚´ãƒªã€‚å¿…é ˆã€‚å–ã‚Šã†ã‚‹å€¤: è«–æ–‡, è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸, ãã®ä»–, ä¸æ˜")
    extracted_data: Optional[Union[AuthorData, InvoiceData, OtherData, Dict[str, Any]]] = Field( 
        None, 
        description="åˆ†é¡ã«å¿œã˜ãŸæŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚ä¸æ˜ã®å ´åˆã¯ null ã«ã—ã¦ãã ã•ã„ã€‚"
    )
    reasoning: str = Field(description="ãã®åˆ†é¡ã¨æŠ½å‡ºã‚’è¡Œã£ãŸæ ¹æ‹ ã€‚")
    transcript: Optional[str] = Field(None, description="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥åŠ›ã•ã‚ŒãŸå ´åˆã®æ–‡å­—èµ·ã“ã—çµæœã€‚")

# ----------------------------------------------------------------------
# 2. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å‡¦ç†æ©Ÿèƒ½ (ãƒ•ã‚¡ã‚¤ãƒ«æŠ½å‡ºã¨ãƒ­ãƒ¼ã‚«ãƒ«AIé€£æº)
# ----------------------------------------------------------------------

# --- (extract_text é–¢æ•°ã¯å¤‰æ›´ãªã—) ---
def extract_text(uploaded_file: st.runtime.uploaded_file_manager.UploadedFile) -> tuple[str, bool]:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°ã€‚
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Œæ–‡å­—èµ·ã“ã—ãŒå¿…è¦ã€ã¨ã—ã¦ãƒ•ãƒ©ã‚° (is_asr=True) ã‚’è¿”ã™ã€‚
    """
    file_ext = uploaded_file.name.split('.')[-1].lower()
    
    # å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®ãƒã‚§ãƒƒã‚¯
    supported_extensions = ['pdf', 'docx', 'xlsx', 'pptx', 'csv', 'mp3', 'wav', 'm4a']
    if file_ext not in supported_extensions:
        return f"ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ '{file_ext}' ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚", False

    # --- éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† (ãƒ•ãƒ©ã‚°ã‚’è¿”ã™) ---
    if file_ext in ['mp3', 'wav', 'm4a']:
        st.info(f"ğŸ”Š éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ­ãƒ¼ã‚«ãƒ«ASRå‡¦ç†ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        return uploaded_file.name, True 

    # --- PDF å‡¦ç† (å®‰å®šæ€§å¼·åŒ–) ---
    if file_ext == 'pdf':
        try:
            st.info(f"ğŸ“„ PDFãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            pdf_reader = pypdf.PdfReader(uploaded_file)
            text_content = ""
            for page in pdf_reader.pages:
                try:
                    text_content += page.extract_text() or ""
                except (TypeError, ValueError) as e:
                    st.warning(f"âš ï¸ ãƒšãƒ¼ã‚¸æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                    continue
                
            if not text_content.strip():
                st.warning("âš ï¸ PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒ£ãƒ³ç”»åƒã¨è¦‹ãªã—ã¦ãƒ¢ãƒƒã‚¯OCRãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                text_content = "OCRçµæœ: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯2024å¹´4æœˆ1æ—¥ã«ç™ºè¡Œã•ã‚ŒãŸé ˜åæ›¸ã§ã‚ã‚Šã€é‡‘é¡ã¯25,000å††ã§ã™ã€‚ç™ºè¡Œå…ƒã¯ABCã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°ã§ã™ã€‚"
            
            return text_content, False
        
        except Exception as e:
            st.error(f"ğŸš¨ PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"PDFå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- DOCX å‡¦ç† ---
    elif file_ext == 'docx':
        try:
            st.info(f"ğŸ“„ DOCXãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            document = docx.Document(io.BytesIO(uploaded_file.getvalue()))
            text_content = ""
            for paragraph in document.paragraphs:
                text_content += paragraph.text + '\n' 
                
            if not text_content.strip():
                st.warning("âš ï¸ DOCXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãŒç©ºã‹ã€èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
            return text_content, False

        except Exception as e:
            st.error(f"ğŸš¨ DOCXå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"DOCXå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- XLSX å‡¦ç† ---
    elif file_ext == 'xlsx':
        try:
            st.info(f"ğŸ“Š XLSXãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            workbook = openpyxl.load_workbook(uploaded_file, read_only=True)
            text_content = ""
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                text_content += f"\n--- ã‚·ãƒ¼ãƒˆ: {sheet_name} ---\n"
                
                for row in sheet.iter_rows():
                    row_data = []
                    for cell in row:
                         if cell.value is not None:
                            row_data.append(str(cell.value))
                    if row_data:
                        text_content += ', '.join(row_data) + '\n'
            
            if not text_content.strip():
                st.warning("âš ï¸ XLSXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            return text_content, False

        except Exception as e:
            st.error(f"ğŸš¨ XLSXå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"XLSXå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- PPTX å‡¦ç† (å®‰å®šæ€§å¼·åŒ–) ---
    elif file_ext == 'pptx':
        try:
            st.info(f"ğŸ–¼ï¸ PPTXãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            presentation = Presentation(uploaded_file)
            text_content = ""
            
            for i, slide in enumerate(presentation.slides):
                text_content += f"\n--- ã‚¹ãƒ©ã‚¤ãƒ‰ {i+1} ---\n"
                for shape in slide.shapes:
                    if hasattr(shape, "text_frame") and shape.text_frame: # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                        text_content += shape.text + '\n'
                    elif shape.has_table:
                        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒ«å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆã‚Šç¢ºå®Ÿã«å–å¾—
                        for row in shape.table.rows:
                            row_data = []
                            for cell in row.cells:
                                if cell.text_frame:
                                    row_data.append(cell.text)
                            text_content += ' | '.join(row_data) + '\n'
                    elif shape.has_text_frame: # has_text_frameã¯text_frameã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯
                        text_content += shape.text_frame.text + '\n'

            if not text_content.strip():
                st.warning("âš ï¸ PPTXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

            return text_content, False
        
        except Exception as e:
            st.error(f"ğŸš¨ PPTXå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"PPTXå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- CSV å‡¦ç† ---
    elif file_ext == 'csv':
        try:
            st.info(f"ğŸ“‹ CSVãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            text_stream = io.StringIO(uploaded_file.getvalue().decode('utf-8'))
            reader = csv.reader(text_stream)
            
            text_content = ""
            for row in reader:
                text_content += ', '.join(row) + '\n'

            if not text_content.strip():
                st.warning("âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã‹ã€èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

            return text_content, False

        except Exception as e:
            st.error(f"ğŸš¨ CSVå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"CSVå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False
            

# --- Gemini APIé€£æºã‚’ç½®ãæ›ãˆã‚‹ãƒ­ãƒ¼ã‚«ãƒ«åˆ†æé–¢æ•°ã«ä¿®æ­£ ---
def analyze_file_content(text_content: str, uploaded_file: st.runtime.uploaded_file_manager.UploadedFile, is_asr: bool) -> AICoreResponse:
    """
    Gemini APIã®ä»£ã‚ã‚Šã«ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’åˆ†æã—ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    
    # ------------------------------------------------------------------
    # 0. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† (æ–‡å­—èµ·ã“ã—ã¨åˆ†æ)
    # ------------------------------------------------------------------
    if is_asr:
        # âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ãƒ¢ãƒƒã‚¯ (è¦ä»¶ 4. ASR)
        transcript = "ãƒ¢ãƒƒã‚¯æ–‡å­—èµ·ã“ã—: 2023å¹´10æœˆ5æ—¥ã€ç”°ä¸­å•†äº‹ã‹ã‚‰15000å††ã®è«‹æ±‚æ›¸ã‚’å—é ˜ã—ã¾ã—ãŸã€‚ä»¶åã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚"
        st.info("ğŸ” **åˆ†æé–‹å§‹**: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãŸã‚ã€æ–‡å­—èµ·ã“ã—çµæœï¼ˆãƒ¢ãƒƒã‚¯ï¼‰ã«åŸºã¥ãæ–‡æ›¸åˆ†é¡ã‚’è¡Œã„ã¾ã™ã€‚")
        
        # ãƒ¢ãƒƒã‚¯ã®æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ï¼ˆæ–‡å­—èµ·ã“ã—çµæœã«åŸºã¥ãã¨ä»®å®šï¼‰
        data = InvoiceData(
            invoice_date="2023-10-05",
            invoice_amount="15000å††",
            invoice_issuer="ç”°ä¸­å•†äº‹",
            invoice_subject="ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ©ã‚¤ã‚»ãƒ³ã‚¹"
        )
        return AICoreResponse(
            category="è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸",
            extracted_data=data,
            reasoning="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ãƒ­ãƒ¼ã‚«ãƒ«ASRãƒ¢ãƒƒã‚¯ã«ã‚ˆã‚Šæ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã€ãã®çµæœã‹ã‚‰è«‹æ±‚æƒ…å ±ï¼ˆæ—¥ä»˜ã€é‡‘é¡ã€ç™ºè¡Œå…ƒï¼‰ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚",
            transcript=transcript
        )

    # æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹åˆ†æ (ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹)
    lower_text = text_content.lower()
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã®æº–å‚™: ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«åãªã©ã®ãƒã‚¤ã‚ºã‚’æ’é™¤ã—ã‚„ã™ã„ã‚ˆã†ã€æœ€åˆã®æ•°è¡Œã‚’æŠ½å‡º
    text_lines = [line.strip() for line in text_content.split('\n') if line.strip()]
    first_10_lines = '\n'.join(text_lines[:10]).strip() 
    
    # å‡¦ç†çŠ¶æ³ã®è¡¨ç¤º
    st.info("ğŸ” **åˆ†æé–‹å§‹**: æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ«ãƒ¼ãƒ«ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚")
    
    # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°åŸºæº–
    score_invoice = 0
    score_author_doc = 0 # è«–æ–‡/è‘—è€…ä»˜ãæ–‡æ›¸ã®ã‚¹ã‚³ã‚¢
    
    # ------------------------------------------------------------------
    # 1. è«‹æ±‚æ›¸/é ˜åæ›¸ ãƒ«ãƒ¼ãƒ« (ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹)
    # ------------------------------------------------------------------
    
    st.info("ã‚¹ãƒ†ãƒƒãƒ— 1: è«‹æ±‚æ›¸/é ˜åæ›¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã€‚")
    
    invoice_keywords = ["è«‹æ±‚æ›¸", "é ˜åæ›¸", "æ˜ç´°", "invoice", "receipt", "åˆè¨ˆé‡‘é¡", "å¾¡ä¸­"]
    if any(keyword in lower_text for keyword in invoice_keywords):
        score_invoice += 5
        st.info(f"â†’ è«‹æ±‚æ›¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º (+5ç‚¹, ç¾åœ¨{score_invoice}ç‚¹)")
    
    # æ—¥ä»˜ã¨é‡‘é¡ã®æ­£è¦è¡¨ç¾ã¯ã€è«‹æ±‚æ›¸ã®ã‚¹ã‚³ã‚¢åˆ¤å®šã‚’å¼·åŒ–
    date_match = re.search(r"(\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}æ—¥?)", first_10_lines)
    amount_match = re.search(r"([Â¥ï¿¥$â‚¬Â£]\s*[\d,]+\.?\d*|[\d,]+\s*(å††|yen))", first_10_lines)
    
    if date_match:
        score_invoice += 5 
        st.info(f"â†’ ãƒ˜ãƒƒãƒ€ãƒ¼ã§æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º (+5ç‚¹, ç¾åœ¨{score_invoice}ç‚¹)")
    if amount_match:
        score_invoice += 5 
        st.info(f"â†’ ãƒ˜ãƒƒãƒ€ãƒ¼ã§é‡‘é¡ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º (+5ç‚¹, ç¾åœ¨{score_invoice}ç‚¹)")
    
    # ------------------------------------------------------------------
    # 2. è‘—è€…ä»˜ãæ–‡æ›¸ ãƒ«ãƒ¼ãƒ« (ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹)
    # ------------------------------------------------------------------
    
    st.info("ã‚¹ãƒ†ãƒƒãƒ— 2: è‘—è€…ä»˜ãæ–‡æ›¸ï¼ˆè«–æ–‡/ãƒ¬ãƒãƒ¼ãƒˆï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã€‚")

    author_doc_keywords = [
        "abstract", "introduction", "author", 
        "æŠ„éŒ²", "ç·’è¨€", "åºè«–", "è‘—è€…", "ç™ºè¡¨å¹´", "ç ”ç©¶å ±å‘Š", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", 
        "ãƒ¬ãƒãƒ¼ãƒˆ", "Report", "æŠ€è¡“è³‡æ–™", "ä½œæˆè€…", "åŸ·ç­†è€…"
    ]
    if any(keyword in lower_text for keyword in author_doc_keywords):
        score_author_doc += 5
        st.info(f"â†’ è‘—è€…ä»˜ãæ–‡æ›¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º (+5ç‚¹, ç¾åœ¨{score_author_doc}ç‚¹)")
    
    # è‘—è€…åã®æ¤œå‡ºã¨æŠ½å‡º (æ—¥æœ¬èªå¯¾å¿œã‚’å¼·åŒ–)
    detected_author = None
    extracted_title = None # æœ€çµ‚çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ä¿æŒã™ã‚‹å¤‰æ•°

    # æ—¥æœ¬èªãƒ»è‹±èªã®æ°åãƒ‘ã‚¿ãƒ¼ãƒ³ (æ¼¢å­—, ã²ã‚‰ãŒãª, ã‚«ã‚¿ã‚«ãƒŠ, ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆ)
    # æ°åã®ã¿ã‚’ç¢ºå®Ÿã«ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
    name_re_ja = r"([ä¸€-é¾ ã‚¡-ãƒ´ãƒ¼ã‚-ã‚“]{2,5}(?:\s*[ä¸€-é¾ ã‚¡-ãƒ´ãƒ¼ã‚-ã‚“]{1,5})*)" 
    name_re_en = r"([A-Z][a-z]+(?:\s[A-Z][a-z\.]*)*)" 
    
    org_keywords_re = r"(?:å¤§å­¦|ç ”ç©¶å®¤|æ ªå¼ä¼šç¤¾|School of|University|Dept)"

    # ãƒ˜ãƒƒãƒ€ãƒ¼å†…ã®è¡Œãƒªã‚¹ãƒˆ
    header_lines = text_lines[:10]
    
    st.info("â†’ æ§‹é€ çš„ãªè‘—è€…åãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã‚¿ã‚¤ãƒˆãƒ«å€™è£œã‚’æ¢ç´¢ä¸­...")
    
    # --- 2-1. ã‚¿ã‚¤ãƒˆãƒ«è¡Œã¨è‘—è€…åã‚’åŒæ™‚ã«æ¢ã—ã€ä½ç½®é–¢ä¿‚ã§ç‰¹å®šã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ ---
    
    best_title_candidate = ""
    best_author_candidate = None
    
    for i in range(len(header_lines)):
        line = header_lines[i]
        
        # 1. è‘—è€…åï¼ˆæ°åã®ã¿ï¼‰ã‚’æ¢ã™ãƒ­ã‚¸ãƒƒã‚¯
        current_line_is_author = False
        author_match = re.match(name_re_ja + r"$", line) or re.match(name_re_en + r"$", line)
        
        if author_match:
            # è‘—è€…åã®å¯èƒ½æ€§ãŒé«˜ã„
            current_line_is_author = True
            
            # ä¿¡é ¼æ€§ãƒã‚§ãƒƒã‚¯: æ¬¡ã®è¡ŒãŒæ‰€å±æ©Ÿé–¢ã§ã‚ã‚‹ã‹ï¼Ÿ
            if i + 1 < len(header_lines) and re.search(org_keywords_re, header_lines[i+1], re.IGNORECASE):
                # æ°åè¡Œã®å¾Œã«æ‰€å±æ©Ÿé–¢ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ã“ã‚Œã¯ç¢ºå®Ÿãªè‘—è€…æƒ…å ±ã€‚
                best_author_candidate = author_match.group(1).strip()
                st.info(f"â†’ è‘—è€…åãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º: {best_author_candidate}")

                # è‘—è€…åã®ç›´å‰ã‚’ã‚¿ã‚¤ãƒˆãƒ«å€™è£œã¨ã™ã‚‹ (ã‚¿ã‚¤ãƒˆãƒ«ãŒè‘—è€…åã®ç›´å‰ã«ã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œ)
                if i > 0:
                    prev_line = header_lines[i-1].strip()
                    # ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«æƒ…å ±ã§ã¯ãªã„ã€ã‚ã‚‹ç¨‹åº¦ã®é•·ã•ãŒã‚ã‚‹è¡Œã‚’ã‚¿ã‚¤ãƒˆãƒ«å€™è£œã¨ã™ã‚‹
                    if len(prev_line) > 15 and not re.search(r"Vol\.\s*\d+|Journal|ISSN|doi|SCU", prev_line, re.IGNORECASE):
                        if 'æŠ„éŒ²' not in prev_line and 'Abstract' not in prev_line:
                            best_title_candidate = prev_line
                            st.info(f"â†’ ã‚¿ã‚¤ãƒˆãƒ«å€™è£œï¼ˆç›´å‰è¡Œï¼‰ã‚’æ¤œå‡º: {best_title_candidate[:20]}...")
                            
                # æœ€ã‚‚ç¢ºå®Ÿãªæƒ…å ±ãŒè¦‹ã¤ã‹ã£ãŸã®ã§ã€ãƒ«ãƒ¼ãƒ—ã‚’çµ‚äº†
                break

        # 2. æ°åã§ã¯ãªã„ã€æœ€ã‚‚é•·ã„è¡Œã‚’æš«å®šã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦ä¿æŒ
        if not current_line_is_author and len(line) > 20 and not re.search(r"Vol\.\s*\d+|Journal|ISSN|doi|SCU|æŠ„éŒ²|Abstract", line, re.IGNORECASE):
            # è‘—è€…ãŒã¾ã è¦‹ã¤ã‹ã£ã¦ã„ãªã„å ´åˆã®ã¿ã€æš«å®šã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦ä¿æŒï¼ˆå¾Œã®è¦ç´„ç”¨ï¼‰
             if len(line) > len(best_title_candidate):
                 best_title_candidate = line
                 
    # è‘—è€…æƒ…å ±ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€ã‚¹ã‚³ã‚¢ã‚’ç¢ºå®šã•ã›ã‚‹
    if best_author_candidate: 
        detected_author = re.sub(r"[\sã€€]", "", best_author_candidate) # æ°åã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        score_author_doc = max(score_author_doc, 10) # å°‘ãªãã¨ã‚‚10ç‚¹ä»¥ä¸Šã‚’ä¿è¨¼
        st.info(f"âœ… è‘—è€…åç¢ºå®š: {detected_author}")
        
    # ------------------------------------------------------------------
    # 3. æœ€çµ‚åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
    # ------------------------------------------------------------------
    
    reasoning_detail = f"ï¼ˆè‘—è€…æ–‡æ›¸ã‚¹ã‚³ã‚¢: {score_author_doc}, è«‹æ±‚æ›¸ã‚¹ã‚³ã‚¢: {score_invoice}ï¼‰"
    
    # è‘—è€…ä»˜ãæ–‡æ›¸ã¨åˆ¤å®š
    if score_author_doc >= 10 and score_author_doc > score_invoice:
        st.success(f"âœ… **æœ€çµ‚åˆ¤å®š**: è‘—è€…ä»˜ãæ–‡æ›¸ï¼ˆè«–æ–‡/ãƒ¬ãƒãƒ¼ãƒˆï¼‰ã¨æ±ºå®šã—ã¾ã—ãŸã€‚")
        
        # æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ï¼ˆè‘—è€…ä»˜ãæ–‡æ›¸ï¼‰
        author = detected_author if detected_author else "è‘—è€…åä¸æ˜"
        title_extracted = os.path.splitext(uploaded_file.name)[0] # åˆæœŸå€¤
        
        # 1. ã‚¿ã‚¤ãƒˆãƒ«å€™è£œãŒã‚ã‚‹å ´åˆ
        if best_title_candidate:
            title_extracted = best_title_candidate
            
        # 2. æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ãŒä¸ååˆ†ã¾ãŸã¯ä¸æ­£ãªå ´åˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆè¦ç´„ã¯ä¿¡é ¼åº¦ã‚¼ãƒ­ã®ãŸã‚ã€ä»Šå›ã¯æ’é™¤ï¼‰
        if not title_extracted or len(title_extracted) < 15 or 'æŠ„éŒ²' in title_extracted.lower() or 'abstract' in title_extracted.lower():
            # æŠ½å‡ºå¤±æ•—ã¨ã¿ãªã—ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ãƒ™ãƒ¼ã‚¹ã«ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
            st.warning("â†’ ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡ºå€™è£œãŒä¸ååˆ†ã¾ãŸã¯ä¸æ­£ãªãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ãƒ™ãƒ¼ã‚¹ã«ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
            title_extracted = os.path.splitext(uploaded_file.name)[0]
        
        # æœ€çµ‚ã‚¿ã‚¤ãƒˆãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        title_extracted = re.sub(r"^(æŠ„éŒ²|Abstract|Keywords):[\s\-\s]*", "", title_extracted, flags=re.IGNORECASE) # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å†åº¦é™¤å»
        
        data = AuthorData( 
            author=author,
            title=title_extracted 
        )
        return AICoreResponse(
            category="è«–æ–‡", # è¦ä»¶å®šç¾©æ›¸ã®åˆ†é¡ã‚«ãƒ†ã‚´ãƒªã¯ã€Œè«–æ–‡ã€ã‚’ç¶­æŒ
            extracted_data=data,
            reasoning=f"é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚Šã€è‘—è€…æƒ…å ±ï¼ˆæ°åã¨æ‰€å±ã®çµ„ã¿åˆã‚ã›ï¼‰ã‚’æ¤œå‡ºï¼ˆ{score_author_doc}ç‚¹ï¼‰ã€‚è‘—è€…ä»˜ãæ–‡æ›¸ã¨åˆ¤å®šã—ã€ã‚¿ã‚¤ãƒˆãƒ«ã¯å†…å®¹ã®è¦ç´„ã«åŸºã¥ãç”Ÿæˆã—ã¾ã—ãŸã€‚",
        )

    # è«‹æ±‚æ›¸ã¨åˆ¤å®š
    elif score_invoice >= 10 and score_invoice >= score_author_doc:
        st.success(f"âœ… **æœ€çµ‚åˆ¤å®š**: è«‹æ±‚æ›¸/é ˜åæ›¸ã¨æ±ºå®šã—ã¾ã—ãŸã€‚")

        # æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ï¼ˆè«‹æ±‚æ›¸ï¼‰
        invoice_date_raw = date_match.group(1) if date_match else "YYYYMMDD"
        invoice_date = invoice_date_raw.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
        
        amount_extracted = amount_match.group(0) if amount_match else "0"
        
        data = InvoiceData(
            invoice_date=invoice_date,
            invoice_amount=amount_extracted,
            invoice_issuer="ä¸æ˜ãªç™ºè¡Œå…ƒ", 
            invoice_subject=uploaded_file.name
        )
        return AICoreResponse(
            category="è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸",
            extracted_data=data,
            reasoning=f"é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚Šã€è«‹æ±‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€æ—¥ä»˜ã€é‡‘é¡ï¼ˆ{score_invoice}ç‚¹ï¼‰ã‚’æ¤œå‡ºã—ã€è«‹æ±‚æ›¸ã¨åˆ¤å®šã—ã¾ã—ãŸã€‚{reasoning_detail}",
        )

    # 4. ãã®ä»–/ä¸æ˜
    if text_content.strip():
        st.warning("âš ï¸ **æœ€çµ‚åˆ¤å®š**: ç‰¹å®šã®æ–‡æ›¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # ãã®ä»–ã«åˆ†é¡ã•ã‚ŒãŸå ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ãã®ã¾ã¾ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦ä½¿ç”¨
        title_generated = os.path.splitext(uploaded_file.name)[0]
        
        data = OtherData(
            title=title_generated
        )
        return AICoreResponse(
            category="ãã®ä»–",
            extracted_data=data,
            reasoning=f"ç‰¹å®šã®æ–‡æ›¸ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆè‘—è€…æ–‡æ›¸ã€è«‹æ±‚æ›¸ï¼‰ã«ä¸€è‡´ã—ã¾ã›ã‚“ã§ã—ãŸã€‚{reasoning_detail} ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…ƒã«ãƒªãƒãƒ¼ãƒ ã—ã¾ã™ã€‚"
        )
    else:
        st.error("âŒ **æœ€çµ‚åˆ¤å®š**: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãŒç©ºã§ã™ã€‚"
        )
        # ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã®å ´åˆ
        return AICoreResponse(
            category="ä¸æ˜",
            extracted_data=None,
            reasoning="ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å†…å®¹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        )


def apply_rename_rule(ai_response: AICoreResponse, original_name: str) -> str:
    """
    è¦ä»¶ 6 ã«åŸºã¥ãã€AIã®å¿œç­”ã‹ã‚‰ãƒªãƒãƒ¼ãƒ å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    base_name, ext = os.path.splitext(original_name)
    category = ai_response.category
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ dict å½¢å¼ã§å–å¾—ã€‚extracted_data ãŒ None ã®å ´åˆã¯ç©ºã® dict ã‚’ä½¿ç”¨
    data = ai_response.extracted_data.model_dump() if ai_response.extracted_data else {} 

    # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã§ããªã„æ–‡å­—ã‚’å‰Šé™¤/ç½®æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def sanitize_filename(name: str) -> str:
        safe_name = name.replace(' ', '_')
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨å¯èƒ½ãªæ–‡å­—ã®ã¿ã‚’è¨±å¯
        return ''.join(c for c in safe_name if c.isalnum() or c in '._-')

    # 4. ä¸æ˜: ãƒªãƒãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—
    if category == "ä¸æ˜":
        st.warning("âš ï¸ ã‚«ãƒ†ã‚´ãƒªãŒã€Œä¸æ˜ã€ã®ãŸã‚ã€ãƒªãƒãƒ¼ãƒ å‡¦ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")
        return original_name

    # 1. è«–æ–‡ (è¦ä»¶ 6.1) -> è‘—è€…ä»˜ãæ–‡æ›¸ã¨ã—ã¦ãƒªãƒãƒ¼ãƒ  (å¹´å·ãªã—)
    elif category == "è«–æ–‡":
        authors = data.get("author", "è‘—è€…åä¸æ˜")
        title = data.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")

        authors_short = authors[:15] if len(authors) > 15 else authors
        # æœ€å¤§50å­—ã®åˆ¶é™ã¯è‘—è€…åã¨ã‚¿ã‚¤ãƒˆãƒ«ã§é©ç”¨
        max_total_len = 50 - 1 # 1ã¯åŒºåˆ‡ã‚Šæ–‡å­— '_' ã®æ•°
        
        # è‘—è€…ã‚’15å­—ã«åˆ¶é™å¾Œã€æ®‹ã‚Šã®æ–‡å­—ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã«å‰²ã‚Šå½“ã¦ã‚‹
        max_title_len = max_total_len - len(authors_short)
        title_short = title[:max(0, max_title_len)]

        # å‘½åè¦å‰‡: è‘—è€…å_ã‚¿ã‚¤ãƒˆãƒ«
        new_name_raw = f"{authors_short}_{title_short}".strip('_')
        return f"{sanitize_filename(new_name_raw)}{ext}"

    # 2. è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸ (è¦ä»¶ 6.2)
    elif category == "è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸":
        date_str_raw = data.get("invoice_date", "YYYYMMDD")
        # æ—¥ä»˜ã«å«ã¾ã‚Œã‚‹æ•°å­—ã ã‘ã‚’å–ã‚Šå‡ºã—ã€8æ¡ã«åˆ¶é™
        date_str = ''.join(filter(str.isdigit, date_str_raw))[:8]

        issuer = data.get("invoice_issuer", "ç™ºè¡Œå…ƒä¸æ˜")[:15]
        
        amount_raw = data.get("invoice_amount", "0")
        # é‡‘é¡ã«å«ã¾ã‚Œã‚‹æ•°å­—ã ã‘ã‚’å–ã‚Šå‡ºã—ã€ã‚«ãƒ³ãƒã‚„é€šè²¨è¨˜å·ã‚’å‰Šé™¤
        amount = ''.join(filter(str.isdigit, amount_raw)) or "0" 
        
        subject = data.get("invoice_subject", "ä»¶åãªã—")[:15]

        new_name_raw = f"{date_str}_{issuer}_{amount}_{subject}"
        return f"{sanitize_filename(new_name_raw)}{ext}"

    # 3. ãã®ä»– (è¦ä»¶ 6.3)
    elif category == "ãã®ä»–":
        title = data.get("title", "AIæ¨æ¸¬ã‚¿ã‚¤ãƒˆãƒ«")[:30]
        return f"{sanitize_filename(title)}{ext}"
    
    # äºˆæœŸã›ã¬åˆ†é¡ã‚¨ãƒ©ãƒ¼
    else:
        st.error(f"ğŸš¨ ãƒªãƒãƒ¼ãƒ ãƒ«ãƒ¼ãƒ«é©ç”¨ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ†ã‚´ãƒª '{category}' ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒä¸æ­£ã§ã™ã€‚å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿”ã—ã¾ã™ã€‚")
        return original_name

# ----------------------------------------------------------------------
# 3. Streamlit UIå®šç¾© (è¦ä»¶ 3)
# ----------------------------------------------------------------------

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ğŸ¤– AIã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (Local Mode)", layout="wide")

## ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    st.markdown("""
    **å‹•ä½œãƒ¢ãƒ¼ãƒ‰:** èª°ã§ã‚‚ä½¿ãˆã‚‹ãƒ­ãƒ¼ã‚«ãƒ«ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰
    
    *Gemini APIã‚’ä½¿ç”¨ã—ãªã„ãŸã‚ã€APIã‚­ãƒ¼ã¯ä¸è¦ã§ã™ã€‚*
    *æ–‡æ›¸åˆ†æã«ã¯Pythonã®æ­£è¦è¡¨ç¾ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚*
    *éŸ³å£°æ–‡å­—èµ·ã“ã—ã¯å›ºå®šã®ãƒ¢ãƒƒã‚¯å¿œç­”ã¨ãªã‚Šã¾ã™ã€‚*
    """)
    
    st.markdown("---")
    st.subheader("å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ (è¦ä»¶ 4)")
    st.markdown("""
    * **æ–‡æ›¸**: PDF, DOCX, XLSX, PPTX, CSV
    * **éŸ³å£°**: MP3, WAV, M4A (ãƒ¢ãƒƒã‚¯)
    """)

## ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
st.title("ğŸ¤– AIã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (Local Mode)")
st.caption("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ«ãƒ¼ãƒ«ã§åˆ†æã—ã€å‘½åãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã‚’è¡Œã„ã¾ã™ã€‚")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ (è¦ä»¶ 3)
uploaded_files = st.file_uploader(
    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (è¤‡æ•°é¸æŠå¯)", 
    type=['pdf', 'docx', 'xlsx', 'pptx', 'csv', 'mp3', 'wav', 'm4a'],
    accept_multiple_files=True
)

if uploaded_files:
    if st.button("ğŸš€ ãƒ­ãƒ¼ã‚«ãƒ«ãƒªãƒãƒ¼ãƒ ãƒ»æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ", use_container_width=True):
        
        # å‡¦ç†çŠ¶æ³ã®è¡¨ç¤º (è¦ä»¶ 3)
        st.subheader("ğŸ“Š å‡¦ç†çµæœ")
        results: List[Dict[str, Any]] = []
        
        progress_bar = st.progress(0)
        
        with st.empty(): 
            for i, uploaded_file in enumerate(uploaded_files):
                
                progress_bar.progress((i + 1) / len(uploaded_files))
                st.info(f"ğŸ‘‰ **{uploaded_file.name}** ã®å‡¦ç†ã‚’é–‹å§‹...")
                
                # 1. ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º/ASRåˆ¤å®š
                text_content, is_asr = extract_text(uploaded_file)
                
                if "å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“" in text_content or "ã‚¨ãƒ©ãƒ¼" in text_content:
                    results.append({
                        "ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                        "å‡¦ç†çŠ¶æ³": "ã‚¹ã‚­ãƒƒãƒ—/ã‚¨ãƒ©ãƒ¼",
                        "åˆ†é¡ã‚«ãƒ†ã‚´ãƒª": "-",
                        "ãƒªãƒãƒ¼ãƒ å¾Œãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                    })
                    continue
                
                # 2. ãƒ­ãƒ¼ã‚«ãƒ«AIã‚³ã‚¢é€£æº
                ai_response = analyze_file_content(text_content, uploaded_file, is_asr)
                
                if ai_response.category == "ä¸æ˜":
                    st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file.name} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç†ç”±: {ai_response.reasoning}")

                # 3. ãƒªãƒãƒ¼ãƒ ãƒ«ãƒ¼ãƒ«é©ç”¨ (è¦ä»¶ 6)
                new_filename = apply_rename_rule(ai_response, uploaded_file.name)
                
                # 4. çµæœã®è¨˜éŒ²ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®è¨­ç½®
                result_data = {
                    "ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                    "å‡¦ç†çŠ¶æ³": "å®Œäº†" if ai_response.category != "ä¸æ˜" else "å¤±æ•—",
                    "åˆ†é¡ã‚«ãƒ†ã‚´ãƒª": ai_response.category,
                    "ãƒªãƒãƒ¼ãƒ å¾Œãƒ•ã‚¡ã‚¤ãƒ«å": new_filename,
                }
                results.append(result_data)
                
                st.markdown(f"**çµæœ ({uploaded_file.name})**:")
                
                col1, col2, col3 = st.columns([1, 1, 2])
                
                with col1:
                    st.download_button(
                        label=f"ğŸ’¾ {new_filename} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=uploaded_file.getvalue(), 
                        file_name=new_filename,
                        mime=uploaded_file.type,
                        key=f"download_renamed_{uploaded_file.name}"
                    )

                if is_asr and ai_response.transcript:
                    with col2:
                        asr_file_name = f"{os.path.splitext(uploaded_file.name)[0]}.txt"
                        st.download_button(
                            label=f"ğŸ“ {asr_file_name} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=ai_response.transcript,
                            file_name=asr_file_name,
                            mime="text/plain",
                            key=f"download_asr_{uploaded_file.name}"
                        )
                
                with col3:
                    st.caption(f"åˆ†é¡: **{ai_response.category}** | ç†ç”±: {ai_response.reasoning}")

            st.success("âœ… å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        st.dataframe(results, use_container_width=True)
        
        st.markdown("---")
        st.subheader("ğŸ’¡ æœ€çµ‚åˆ†æçµæœ (æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿)")
        if 'ai_response' in locals() and ai_response:
            # Pydanticãƒ¢ãƒ‡ãƒ«ã‚’è¾æ›¸ã«å¤‰æ›ã—ã¦è¡¨ç¤º
            st.json(ai_response.model_dump())
        else:
            st.write("ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‡¦ç†ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
