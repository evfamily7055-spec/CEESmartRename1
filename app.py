import streamlit as st
import json
import os
import io
import csv # CSVå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import time # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã®å¾…æ©Ÿç”¨
from pydantic import BaseModel, Field, ValidationError, ConfigDict # ConfigDictã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from typing import Optional, Literal, Dict, Any, List, Union # Unionã‚’è¿½åŠ 
import re # æ­£è¦è¡¨ç¾ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿½åŠ 

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import pypdf # PDFå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import docx # DOCXå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (python-docx)
import openpyxl # XLSXå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from pptx import Presentation # PPTXå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (python-pptx)

# ----------------------------------------------------------------------
# âš ï¸ æ³¨æ„: Gemini APIä¾å­˜ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã€Google Geminiã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ä½¿ç”¨ã—ã¾ã›ã‚“ã€‚
# ----------------------------------------------------------------------

# ----------------------------------------------------------------------
# 1. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å®šç¾© (Pydanticã§ç¶™ç¶š)
# ----------------------------------------------------------------------

# è«–æ–‡ãƒ‡ãƒ¼ã‚¿ => è‘—è€…ä»˜ãæ–‡æ›¸ãƒ‡ãƒ¼ã‚¿ã«åç§°å¤‰æ›´
class AuthorData(BaseModel):
    # year: str = Field(description="å‡ºç‰ˆå¹´è¥¿æš¦ (ä¾‹: 2024)") # å¹´å·ã¯å¿…é ˆã§ã¯ãªã„ãŸã‚ãƒ­ã‚¸ãƒƒã‚¯ã§ã®ã¿åˆ©ç”¨
    author: str = Field(description="ä¸»è¦è‘—è€…åã€‚ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")
    title: str = Field(description="æ–‡æ›¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã€‚")

# è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸ãƒ‡ãƒ¼ã‚¿
class InvoiceData(BaseModel):
    invoice_date: str = Field(description="ç™ºè¡Œæ—¥ã€‚YYYY-MM-DDå½¢å¼ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚")
    invoice_amount: str = Field(description="åˆè¨ˆé‡‘é¡ã€‚æ•°å­—ã¨é€šè²¨è¨˜å·ã‚’å«ã‚“ã å…ƒã®æ–‡å­—åˆ—ã€‚")
    invoice_issuer: str = Field(description="ç™ºè¡Œå…ƒ/ç™ºè¡Œè€…åã€‚")
    invoice_subject: str = Field(description="è«‹æ±‚æ›¸/é ˜åæ›¸ã®ä»¶åã€‚")

# ãã®ä»–ãƒ‡ãƒ¼ã‚¿
class OtherData(BaseModel):
    title: str = Field(description="ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’æœ€ã‚‚ã‚ˆãè¡¨ã™ã€AIãŒæ¨æ¸¬ã—ãŸã‚¿ã‚¤ãƒˆãƒ«ã€‚")

# AIã‚³ã‚¢ã‹ã‚‰ã®æœ€çµ‚å¿œç­”ã‚¹ã‚­ãƒ¼ãƒ
Category = Literal["è«–æ–‡", "è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸", "ãã®ä»–", "ä¸æ˜"]

class AICoreResponse(BaseModel):
    # ä½™åˆ†ãªå…¥åŠ›ã‚’ç„¡è¦–ã™ã‚‹è¨­å®š
    model_config = ConfigDict(extra='ignore')

    category: Category = Field(description="ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†é¡ã‚«ãƒ†ã‚´ãƒªã€‚å¿…é ˆã€‚å–ã‚Šã†ã‚‹å€¤: è«–æ–‡, è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸, ãã®ä»–, ä¸æ˜")
    # AuthorData (æ—§ PaperData) ã‚’ä½¿ç”¨
    extracted_data: Optional[Union[AuthorData, InvoiceData, OtherData, Dict[str, Any]]] = Field( 
        None, 
        description="åˆ†é¡ã«å¿œã˜ãŸæŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚ä¸æ˜ã®å ´åˆã¯ null ã«ã—ã¦ãã ã•ã„ã€‚"
    )
    reasoning: str = Field(description="ãã®åˆ†é¡ã¨æŠ½å‡ºã‚’è¡Œã£ãŸæ ¹æ‹ ã€‚")
    transcript: Optional[str] = Field(None, description="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥åŠ›ã•ã‚ŒãŸå ´åˆã®æ–‡å­—èµ·ã“ã—çµæœã€‚")

# ----------------------------------------------------------------------
# 2. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å‡¦ç†æ©Ÿèƒ½ (ãƒ•ã‚¡ã‚¤ãƒ«æŠ½å‡ºã¨ãƒ­ãƒ¼ã‚«ãƒ«AIé€£æº)
# ----------------------------------------------------------------------

# --- (extract_text é–¢æ•°ã¯å¤‰æ›´ãªã—) ---
def extract_text(uploaded_file: st.runtime.uploaded_file_manager.UploadedFile) -> tuple[str, bool]:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°ã€‚
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Œæ–‡å­—èµ·ã“ã—ãŒå¿…è¦ã€ã¨ã—ã¦ãƒ•ãƒ©ã‚° (is_asr=True) ã‚’è¿”ã™ã€‚
    """
    file_ext = uploaded_file.name.split('.')[-1].lower()
    
    # å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®ãƒã‚§ãƒƒã‚¯
    supported_extensions = ['pdf', 'docx', 'xlsx', 'pptx', 'csv', 'mp3', 'wav', 'm4a']
    if file_ext not in supported_extensions:
        return f"ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ '{file_ext}' ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚", False

    # --- éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† (ãƒ•ãƒ©ã‚°ã‚’è¿”ã™) ---
    if file_ext in ['mp3', 'wav', 'm4a']:
        st.info(f"ğŸ”Š éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ­ãƒ¼ã‚«ãƒ«ASRå‡¦ç†ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        # âš ï¸ Geminiã‚’ä½¿ã‚ãªã„ãŸã‚ã€ASRã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ¢ãƒƒã‚¯ã¨ã—ã¦å‡¦ç†ã™ã‚‹
        return uploaded_file.name, True 

    # --- PDF å‡¦ç† (å®‰å®šæ€§å¼·åŒ–) ---
    if file_ext == 'pdf':
        try:
            st.info(f"ğŸ“„ PDFãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            pdf_reader = pypdf.PdfReader(uploaded_file)
            text_content = ""
            for page in pdf_reader.pages:
                try:
                    text_content += page.extract_text() or ""
                except (TypeError, ValueError) as e:
                    st.warning(f"âš ï¸ ãƒšãƒ¼ã‚¸æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                    continue
                
            if not text_content.strip():
                st.warning("âš ï¸ PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒ£ãƒ³ç”»åƒã¨è¦‹ãªã—ã¦ãƒ¢ãƒƒã‚¯OCRãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                text_content = "OCRçµæœ: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯2024å¹´4æœˆ1æ—¥ã«ç™ºè¡Œã•ã‚ŒãŸé ˜åæ›¸ã§ã‚ã‚Šã€é‡‘é¡ã¯25,000å††ã§ã™ã€‚ç™ºè¡Œå…ƒã¯ABCã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°ã§ã™ã€‚"
            
            return text_content, False
        
        except Exception as e:
            st.error(f"ğŸš¨ PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"PDFå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- DOCX å‡¦ç† ---
    elif file_ext == 'docx':
        try:
            st.info(f"ğŸ“„ DOCXãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            document = docx.Document(io.BytesIO(uploaded_file.getvalue()))
            text_content = ""
            for paragraph in document.paragraphs:
                text_content += paragraph.text + '\n' 
                
            if not text_content.strip():
                st.warning("âš ï¸ DOCXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãŒç©ºã‹ã€èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
            return text_content, False

        except Exception as e:
            st.error(f"ğŸš¨ DOCXå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"DOCXå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- XLSX å‡¦ç† ---
    elif file_ext == 'xlsx':
        try:
            st.info(f"ğŸ“Š XLSXãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            workbook = openpyxl.load_workbook(uploaded_file, read_only=True)
            text_content = ""
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                text_content += f"\n--- ã‚·ãƒ¼ãƒˆ: {sheet_name} ---\n"
                
                for row in sheet.iter_rows():
                    row_data = []
                    for cell in row:
                         if cell.value is not None:
                            row_data.append(str(cell.value))
                    if row_data:
                        text_content += ', '.join(row_data) + '\n'
            
            if not text_content.strip():
                st.warning("âš ï¸ XLSXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            return text_content, False

        except Exception as e:
            st.error(f"ğŸš¨ XLSXå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"XLSXå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- PPTX å‡¦ç† (å®‰å®šæ€§å¼·åŒ–) ---
    elif file_ext == 'pptx':
        try:
            st.info(f"ğŸ–¼ï¸ PPTXãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            presentation = Presentation(uploaded_file)
            text_content = ""
            
            for i, slide in enumerate(presentation.slides):
                text_content += f"\n--- ã‚¹ãƒ©ã‚¤ãƒ‰ {i+1} ---\n"
                for shape in slide.shapes:
                    if hasattr(shape, "text_frame") and shape.text_frame: # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                        text_content += shape.text + '\n'
                    elif shape.has_table:
                        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒ«å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆã‚Šç¢ºå®Ÿã«å–å¾—
                        for row in shape.table.rows:
                            row_data = []
                            for cell in row.cells:
                                if cell.text_frame:
                                    row_data.append(cell.text)
                            text_content += ' | '.join(row_data) + '\n'
                    elif shape.has_text_frame: # has_text_frameã¯text_frameã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯
                        text_content += shape.text_frame.text + '\n'

            if not text_content.strip():
                st.warning("âš ï¸ PPTXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

            return text_content, False
        
        except Exception as e:
            st.error(f"ğŸš¨ PPTXå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"PPTXå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False

    # --- CSV å‡¦ç† ---
    elif file_ext == 'csv':
        try:
            st.info(f"ğŸ“‹ CSVãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}): ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
            text_stream = io.StringIO(uploaded_file.getvalue().decode('utf-8'))
            reader = csv.reader(text_stream)
            
            text_content = ""
            for row in reader:
                text_content += ', '.join(row) + '\n'

            if not text_content.strip():
                st.warning("âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã‹ã€èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

            return text_content, False

        except Exception as e:
            st.error(f"ğŸš¨ CSVå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"CSVå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", False
            

# --- Gemini APIé€£æºã‚’ç½®ãæ›ãˆã‚‹ãƒ­ãƒ¼ã‚«ãƒ«åˆ†æé–¢æ•°ã«ä¿®æ­£ ---
def analyze_file_content(text_content: str, uploaded_file: st.runtime.uploaded_file_manager.UploadedFile, is_asr: bool) -> AICoreResponse:
    """
    Gemini APIã®ä»£ã‚ã‚Šã«ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’åˆ†æã—ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    
    # ------------------------------------------------------------------
    # 0. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† (æ–‡å­—èµ·ã“ã—ã¨åˆ†æ)
    # ------------------------------------------------------------------
    if is_asr:
        # âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ãƒ¢ãƒƒã‚¯ (è¦ä»¶ 4. ASR)
        transcript = "ãƒ¢ãƒƒã‚¯æ–‡å­—èµ·ã“ã—: 2023å¹´10æœˆ5æ—¥ã€ç”°ä¸­å•†äº‹ã‹ã‚‰15000å††ã®è«‹æ±‚æ›¸ã‚’å—é ˜ã—ã¾ã—ãŸã€‚ä»¶åã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚"
        st.info("ğŸ” **åˆ†æé–‹å§‹**: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãŸã‚ã€æ–‡å­—èµ·ã“ã—çµæœï¼ˆãƒ¢ãƒƒã‚¯ï¼‰ã«åŸºã¥ãæ–‡æ›¸åˆ†é¡ã‚’è¡Œã„ã¾ã™ã€‚")
        
        # ãƒ¢ãƒƒã‚¯ã®æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ï¼ˆæ–‡å­—èµ·ã“ã—çµæœã«åŸºã¥ãã¨ä»®å®šï¼‰
        data = InvoiceData(
            invoice_date="2023-10-05",
            invoice_amount="15000å††",
            invoice_issuer="ç”°ä¸­å•†äº‹",
            invoice_subject="ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ©ã‚¤ã‚»ãƒ³ã‚¹"
        )
        return AICoreResponse(
            category="è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸",
            extracted_data=data,
            reasoning="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ãƒ­ãƒ¼ã‚«ãƒ«ASRãƒ¢ãƒƒã‚¯ã«ã‚ˆã‚Šæ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã€ãã®çµæœã‹ã‚‰è«‹æ±‚æƒ…å ±ï¼ˆæ—¥ä»˜ã€é‡‘é¡ã€ç™ºè¡Œå…ƒï¼‰ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚",
            transcript=transcript
        )

    # æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹åˆ†æ (ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹)
    lower_text = text_content.lower()
    first_10_lines = '\n'.join(text_content.split('\n')[:10]).strip() # å…ˆé ­10è¡Œã‚’åˆ†æ
    
    # å‡¦ç†çŠ¶æ³ã®è¡¨ç¤º
    st.info("ğŸ” **åˆ†æé–‹å§‹**: æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ«ãƒ¼ãƒ«ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚")
    
    # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°åŸºæº–
    score_invoice = 0
    score_author_doc = 0 # è«–æ–‡/è‘—è€…ä»˜ãæ–‡æ›¸ã®ã‚¹ã‚³ã‚¢
    
    # ------------------------------------------------------------------
    # 1. è«‹æ±‚æ›¸/é ˜åæ›¸ ãƒ«ãƒ¼ãƒ« (ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹)
    # ------------------------------------------------------------------
    
    invoice_keywords = ["è«‹æ±‚æ›¸", "é ˜åæ›¸", "æ˜ç´°", "invoice", "receipt", "åˆè¨ˆé‡‘é¡", "å¾¡ä¸­"]
    if any(keyword in lower_text for keyword in invoice_keywords):
        score_invoice += 5
        st.info(f"â†’ è«‹æ±‚æ›¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º ({score_invoice}ç‚¹)")
    
    date_match = re.search(r"(\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}æ—¥?)", first_10_lines)
    amount_match = re.search(r"([Â¥ï¿¥$â‚¬Â£]\s*[\d,]+\.?\d*|[\d,]+\s*(å††|yen))", first_10_lines)
    
    if date_match:
        score_invoice += 5 # æ—¥ä»˜æ¤œå‡º
        st.info(f"â†’ ãƒ˜ãƒƒãƒ€ãƒ¼ã§æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º (+5ç‚¹, ç¾åœ¨{score_invoice}ç‚¹)")
    if amount_match:
        score_invoice += 5 # é‡‘é¡æ¤œå‡º
        st.info(f"â†’ ãƒ˜ãƒƒãƒ€ãƒ¼ã§é‡‘é¡ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º (+5ç‚¹, ç¾åœ¨{score_invoice}ç‚¹)")
    
    # ------------------------------------------------------------------
    # 2. è‘—è€…ä»˜ãæ–‡æ›¸ ãƒ«ãƒ¼ãƒ« (ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹)
    # ------------------------------------------------------------------
    
    author_doc_keywords = [
        "abstract", "introduction", "author", "year of publication", # è«–æ–‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        "æŠ„éŒ²", "ç·’è¨€", "åºè«–", "è‘—è€…", "ç™ºè¡¨å¹´", "ç ”ç©¶å ±å‘Š", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", # è«–æ–‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        "ãƒ¬ãƒãƒ¼ãƒˆ", "Report", "æŠ€è¡“è³‡æ–™", "ä½œæˆè€…", "åŸ·ç­†è€…" # ä¸€èˆ¬çš„ãªè‘—è€…ä»˜ãæ–‡æ›¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
    ]
    if any(keyword in lower_text for keyword in author_doc_keywords):
        score_author_doc += 5
        st.info(f"â†’ è‘—è€…ä»˜ãæ–‡æ›¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º ({score_author_doc}ç‚¹)")
    
    # [ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ] è‘—è€…åæ¤œå‡ºã®æ­£è¦è¡¨ç¾ã‚’æ—¥æœ¬èªåã¨è‹±èªåã«å¯¾å¿œã•ã›ã‚‹
    # ä¿®æ­£å‰: author_pattern = re.search(r"(?:Author|è‘—è€…|ä½œæˆè€…|åŸ·ç­†è€…)\s*[:]?\s*([A-Z][a-z]+(?:\s*[A-Z][a-z]+)?)\s*(?:\((.+?)\))?", first_10_lines)
    # ä¿®æ­£å¾Œ: æ°åãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã€Œæ¼¢å­—/ã²ã‚‰ãŒãª/ã‚«ã‚¿ã‚«ãƒŠã€ã¾ãŸã¯ã€Œè‹±èªåã€ã®ã„ãšã‚Œã‹ã«åºƒãå¯¾å¿œã•ã›ã‚‹
    
    # è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³: ã€Œè‘—è€…åï¼ˆæ‰€å±ï¼‰ã€ã¾ãŸã¯ã€Œè‘—è€…åï¼ˆæ”¹è¡Œï¼‰æ‰€å±ã€ã‚’æ‰ãˆã‚‹ã€‚
    # [^:]*?: ã‚³ãƒ­ãƒ³ä»¥å¤–ã®ä»»æ„ã®æ–‡å­—ï¼ˆæ°å/ã‚¿ã‚¤ãƒˆãƒ«ï¼‰
    # (?:Author|è‘—è€…|ä½œæˆè€…|åŸ·ç­†è€…): ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã„ãšã‚Œã‹
    # ([A-Z][a-z]+(?:\s*[A-Z][a-z]+)?): è‹±èªåãƒ‘ã‚¿ãƒ¼ãƒ³
    # (?:[\u3005\u3006\u303b\u4e00-\u9faf\u3040-\u309f\u30a0-\u30ff]+) : æ—¥æœ¬èªåãƒ‘ã‚¿ãƒ¼ãƒ³
    
    # ä»Šå›ã¯ã€ã‚·ãƒ³ãƒ—ãƒ«ã«ã€Œè‘—è€…åã®å¾Œã«æ‰€å±æ©Ÿé–¢åãŒç¶šããƒ‘ã‚¿ãƒ¼ãƒ³ã€ã‚’å¹…åºƒãã‚«ãƒãƒ¼ã™ã‚‹
    author_pattern_match = re.search(
        r"(?:Author|è‘—è€…|ä½œæˆè€…|åŸ·ç­†è€…)[:\s]*\s*([^,\n]+?)\s*(\([^\n]+\)|[^\n]*\s*[å¤§|ä¼š|å­¦|ç¤¾|ç§‘|é™¢|éƒ¨|æ ¡][^\n]*)", 
        first_10_lines, 
        re.IGNORECASE | re.DOTALL
    )
    
    # æ—¥æœ¬èª/è‹±èªä¸¡å¯¾å¿œã®è‘—è€…åï¼ˆæ°åã®ã¿ï¼‰ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
    name_pattern = r"([^,\n]+?)" # æ°åã¯ã€æ”¹è¡Œã‚„ã‚«ãƒ³ãƒã¾ã§
    
    # ã€Œæ°å + æ‰€å±ã€ã¾ãŸã¯ã€Œæ°å + å½¹è·ã€ãŒãƒ˜ãƒƒãƒ€ãƒ¼ã«ã‚ã‚‹ã‹
    author_pattern = re.search(
        r"(?:Author|è‘—è€…|ä½œæˆè€…|åŸ·ç­†è€…)[\s:]*?(" + name_pattern + r")\s*(\([^\)]+\)|[^\n]+\s*[å¤§|å­¦|ç¤¾|ä¼š|ç§‘|é™¢|éƒ¨|æ ¡][^\n]*?)", 
        first_10_lines, 
        re.IGNORECASE | re.DOTALL
    )
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªã€Œæ°åã€å˜ä½“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¾‹: ç”ºç”°ä½³ä¸–å­ æœ­å¹Œå¸‚ç«‹å¤§å­¦ãƒ‡ã‚¶ã‚¤ãƒ³å­¦éƒ¨)
    # æ°åã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¯›å®¹ã«ã™ã‚‹: ä»»æ„ã®æ–‡å­— (\w) ã‚’å«ã‚€ã€æ”¹è¡Œã‚„ã‚«ãƒ³ãƒã‚’å«ã¾ãªã„æ–‡å­—åˆ—
    author_simple_pattern = re.search(
        r"(?:Author|è‘—è€…|ä½œæˆè€…|åŸ·ç­†è€…)[\s:]*?([^\n,]+)", 
        first_10_lines, 
        re.IGNORECASE
    )
    
    # ä»Šå›ã®PDFã®å½¢å¼ ('ç”ºç”°ä½³ä¸–å­\n æœ­å¹Œå¸‚ç«‹å¤§å­¦ãƒ‡ã‚¶ã‚¤ãƒ³å­¦éƒ¨')ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€
    # è‘—è€…ã®å¾Œã«æ‰€å±æ©Ÿé–¢åï¼ˆæ—¥æœ¬èªã®çµ„ç¹”åã‚’å«ã‚€ï¼‰ãŒç¶šããƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å„ªå…ˆã™ã‚‹
    
    # æ°åï¼ˆæ—¥æœ¬èªã¾ãŸã¯è‹±èªï¼‰ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
    name_capture_group = r"([^,\n\s]+(?:\s[^,\n\s]+)*?)"
    
    # æ°åãŒæ¤œå‡ºã•ã‚Œã€ãã®å¾Œã«æ‰€å±æ©Ÿé–¢ã£ã½ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒç¶šããƒ‘ã‚¿ãƒ¼ãƒ³
    author_doc_match = re.search(
        r"(?:Author|è‘—è€…|ä½œæˆè€…|åŸ·ç­†è€…)[\s:]*?" + name_capture_group + r"\s*([^\n]*?å¤§å­¦|[^\n]*?ç ”ç©¶å®¤|[^\n]*?æ ªå¼ä¼šç¤¾)",
        first_10_lines,
        re.IGNORECASE | re.DOTALL
    )
    
    # æœ€çµ‚çš„ãªè‘—è€…æƒ…å ±æ¤œå‡ºã«ä½¿ç”¨ã™ã‚‹å¤‰æ•°
    detected_author = None
    if author_doc_match:
        detected_author = author_doc_match.group(1).strip()
        st.info(f"â†’ **æ§‹é€ çš„è‘—è€…æƒ…å ±ï¼ˆ{detected_author}ï¼‰**æ¤œå‡º (+10ç‚¹, ç¾åœ¨{score_author_doc}ç‚¹)")
        score_author_doc += 10 # æ§‹é€ çš„ãªè‘—è€…æƒ…å ±æ¤œå‡º
    
    
    year_match = re.search(r"(\d{4})", first_10_lines)
    
    if detected_author: # è‘—è€…åãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
        score_author_doc += 10 # æ§‹é€ çš„ãªè‘—è€…æƒ…å ±æ¤œå‡ºï¼ˆå†åŠ ç®—ã§ã¯ãªãã€ç¢ºå®Ÿã«10ç‚¹ä»¥ä¸Šã«ã™ã‚‹ãŸã‚ã®è£œå¼·ï¼‰
    
    if year_match and score_author_doc > 0:
        score_author_doc += 3 # å¹´å·ãŒæ¤œå‡ºã•ã‚Œã€ã‹ã¤è‘—è€…ä»˜ãæ–‡æ›¸ã®å¯èƒ½æ€§ãŒé«˜ã„å ´åˆ
        st.info(f"â†’ ãƒ˜ãƒƒãƒ€ãƒ¼ã§å¹´å·ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º (+3ç‚¹, ç¾åœ¨{score_author_doc}ç‚¹)")
        
    # ------------------------------------------------------------------
    # 3. æœ€çµ‚åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
    # ------------------------------------------------------------------
    
    reasoning_detail = f"ï¼ˆè‘—è€…æ–‡æ›¸ã‚¹ã‚³ã‚¢: {score_author_doc}, è«‹æ±‚æ›¸ã‚¹ã‚³ã‚¢: {score_invoice}ï¼‰"
    
    # è«–æ–‡/è‘—è€…ä»˜ãæ–‡æ›¸ã¨åˆ¤å®š
    if score_author_doc >= 10 and score_author_doc > score_invoice:
        st.success(f"âœ… **æœ€çµ‚åˆ¤å®š**: è‘—è€…ä»˜ãæ–‡æ›¸ï¼ˆè«–æ–‡/ãƒ¬ãƒãƒ¼ãƒˆï¼‰ã¨æ±ºå®šã—ã¾ã—ãŸã€‚")
        
        # æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ï¼ˆè‘—è€…ä»˜ãæ–‡æ›¸ï¼‰
        author = detected_author if detected_author else "è‘—è€…åä¸æ˜"
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¯ãƒ†ã‚­ã‚¹ãƒˆã®æœ€åˆã®éç©ºç™½è¡Œã¨ã™ã‚‹ (æœ€ã‚‚ç¢ºå®Ÿ)
        # ãŸã ã—ã€æœ€åˆã®è¡ŒãŒè‘—è€…åã§ãªã„ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚‹ (ä»Šå›ã¯æœ€åˆã®è¡ŒãŒã‚¿ã‚¤ãƒˆãƒ«ãªã®ã§OKã¨ã™ã‚‹)
        title_lines = [line for line in text_content.split('\n') if line.strip()]
        
        # æœ€åˆã®3è¡Œã‹ã‚‰æœ€ã‚‚é•·ã„è¡Œã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨è¦‹ãªã™ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæ—¥æœ¬èªæ–‡æ›¸å¯¾å¿œï¼‰
        title_extracted = os.path.splitext(uploaded_file.name)[0] # åˆæœŸå€¤ã¯ãƒ•ã‚¡ã‚¤ãƒ«å
        if len(title_lines) > 0:
            # æœ€åˆã®æ•°è¡Œã®æœ€ã‚‚é•·ã„ã‚‚ã®ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã™ã‚‹
            top_lines = title_lines[:4]
            # è‘—ä½œæ¨©è¡¨è¨˜ï¼ˆCopyrightãªã©ï¼‰ã‚„ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«åã¯é™¤å¤–ã—ãŸã„ãŒã€ã“ã“ã§ã¯æœ€ã‚‚é•·ã„ã‚‚ã®ã‚’æ¡ç”¨
            title_extracted = max(top_lines, key=len)
        
        data = AuthorData( # AuthorDataã‚’ä½¿ç”¨
            author=author,
            title=title_extracted 
        )
        # Yearã¯ãƒªãƒãƒ¼ãƒ å½¢å¼ã‹ã‚‰å‰Šé™¤ã—ãŸãŸã‚ã€æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã«ã¯å«ã‚ãªã„
        return AICoreResponse(
            category="è«–æ–‡", # è¦ä»¶å®šç¾©æ›¸ã®åˆ†é¡ã‚«ãƒ†ã‚´ãƒªã¯ã€Œè«–æ–‡ã€ã‚’ç¶­æŒ
            extracted_data=data,
            reasoning=f"é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚Šã€è‘—è€…æƒ…å ±ï¼ˆæ°åãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡ºï¼ˆ{score_author_doc}ç‚¹ï¼‰ã€‚è‘—è€…ä»˜ãæ–‡æ›¸ã¨åˆ¤å®šã—ã¾ã—ãŸã€‚",
        )

    # è«‹æ±‚æ›¸ã¨åˆ¤å®š
    elif score_invoice >= 10 and score_invoice >= score_author_doc:
        st.success(f"âœ… **æœ€çµ‚åˆ¤å®š**: è«‹æ±‚æ›¸/é ˜åæ›¸ã¨æ±ºå®šã—ã¾ã—ãŸã€‚")

        # æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ï¼ˆè«‹æ±‚æ›¸ï¼‰
        invoice_date_raw = date_match.group(1) if date_match else "YYYYMMDD"
        invoice_date = invoice_date_raw.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
        
        amount_extracted = amount_match.group(0) if amount_match else "0"
        
        data = InvoiceData(
            invoice_date=invoice_date,
            invoice_amount=amount_extracted,
            invoice_issuer="ä¸æ˜ãªç™ºè¡Œå…ƒ", 
            invoice_subject=uploaded_file.name
        )
        return AICoreResponse(
            category="è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸",
            extracted_data=data,
            reasoning=f"é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚Šã€è«‹æ±‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€æ—¥ä»˜ã€é‡‘é¡ï¼ˆ{score_invoice}ç‚¹ï¼‰ã‚’æ¤œå‡ºã—ã€è«‹æ±‚æ›¸ã¨åˆ¤å®šã—ã¾ã—ãŸã€‚{reasoning_detail}",
        )

    # 4. ãã®ä»–/ä¸æ˜
    if text_content.strip():
        st.warning("âš ï¸ **æœ€çµ‚åˆ¤å®š**: ç‰¹å®šã®æ–‡æ›¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
        # ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°ã€Œãã®ä»–ã€ã¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦ææ¡ˆ
        data = OtherData(
            title=os.path.splitext(uploaded_file.name)[0]
        )
        return AICoreResponse(
            category="ãã®ä»–",
            extracted_data=data,
            reasoning=f"ç‰¹å®šã®æ–‡æ›¸ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆè‘—è€…æ–‡æ›¸ã€è«‹æ±‚æ›¸ï¼‰ã«ä¸€è‡´ã—ã¾ã›ã‚“ã§ã—ãŸã€‚{reasoning_detail} ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…ƒã«ãƒªãƒãƒ¼ãƒ ã—ã¾ã™ã€‚"
        )
    else:
        st.error("âŒ **æœ€çµ‚åˆ¤å®š**: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãŒç©ºã§ã™ã€‚")
        # ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã®å ´åˆ
        return AICoreResponse(
            category="ä¸æ˜",
            extracted_data=None,
            reasoning="ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å†…å®¹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        )


def apply_rename_rule(ai_response: AICoreResponse, original_name: str) -> str:
    """
    è¦ä»¶ 6 ã«åŸºã¥ãã€AIã®å¿œç­”ã‹ã‚‰ãƒªãƒãƒ¼ãƒ å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    base_name, ext = os.path.splitext(original_name)
    category = ai_response.category
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ dict å½¢å¼ã§å–å¾—ã€‚extracted_data ãŒ None ã®å ´åˆã¯ç©ºã® dict ã‚’ä½¿ç”¨
    # ãƒ¢ãƒƒã‚¯å‡¦ç†ãªã®ã§ã€Pydanticãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç›´æ¥ dict ã«å¤‰æ› (ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚)
    data = ai_response.extracted_data.model_dump() if ai_response.extracted_data else {} 

    # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã§ããªã„æ–‡å­—ã‚’å‰Šé™¤/ç½®æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def sanitize_filename(name: str) -> str:
        safe_name = name.replace(' ', '_')
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨å¯èƒ½ãªæ–‡å­—ã®ã¿ã‚’è¨±å¯
        return ''.join(c for c in safe_name if c.isalnum() or c in '._-')

    # 4. ä¸æ˜: ãƒªãƒãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—
    if category == "ä¸æ˜":
        st.warning("âš ï¸ ã‚«ãƒ†ã‚´ãƒªãŒã€Œä¸æ˜ã€ã®ãŸã‚ã€ãƒªãƒãƒ¼ãƒ å‡¦ç†ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")
        return original_name

    # 1. è«–æ–‡ (è¦ä»¶ 6.1) -> è‘—è€…ä»˜ãæ–‡æ›¸ã¨ã—ã¦ãƒªãƒãƒ¼ãƒ  (å¹´å·ãªã—)
    elif category == "è«–æ–‡":
        # year = data.get("year", "YYYY") # å¹´å·ã¯ä½¿ç”¨ã—ãªã„
        authors = data.get("author", "è‘—è€…åä¸æ˜")
        title = data.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")

        authors_short = authors[:15] if len(authors) > 15 else authors
        # æœ€å¤§50å­—ã®åˆ¶é™ã¯è‘—è€…åã¨ã‚¿ã‚¤ãƒˆãƒ«ã§é©ç”¨
        max_total_len = 50 - 1 # 1ã¯åŒºåˆ‡ã‚Šæ–‡å­— '_' ã®æ•°
        
        # è‘—è€…ã‚’15å­—ã«åˆ¶é™å¾Œã€æ®‹ã‚Šã®æ–‡å­—ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã«å‰²ã‚Šå½“ã¦ã‚‹
        max_title_len = max_total_len - len(authors_short)
        title_short = title[:max(0, max_title_len)]

        # å‘½åè¦å‰‡: è‘—è€…å_ã‚¿ã‚¤ãƒˆãƒ«
        new_name_raw = f"{authors_short}_{title_short}".strip('_')
        return f"{sanitize_filename(new_name_raw)}{ext}"

    # 2. è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸ (è¦ä»¶ 6.2)
    elif category == "è«‹æ±‚æ›¸ãƒ»é ˜åæ›¸":
        date_str_raw = data.get("invoice_date", "YYYYMMDD")
        # æ—¥ä»˜ã«å«ã¾ã‚Œã‚‹æ•°å­—ã ã‘ã‚’å–ã‚Šå‡ºã—ã€8æ¡ã«åˆ¶é™
        date_str = ''.join(filter(str.isdigit, date_str_raw))[:8]

        issuer = data.get("invoice_issuer", "ç™ºè¡Œå…ƒä¸æ˜")[:15]
        
        amount_raw = data.get("invoice_amount", "0")
        # é‡‘é¡ã«å«ã¾ã‚Œã‚‹æ•°å­—ã ã‘ã‚’å–ã‚Šå‡ºã—ã€ã‚«ãƒ³ãƒã‚„é€šè²¨è¨˜å·ã‚’å‰Šé™¤
        amount = ''.join(filter(str.isdigit, amount_raw)) or "0" 
        
        subject = data.get("invoice_subject", "ä»¶åãªã—")[:15]

        new_name_raw = f"{date_str}_{issuer}_{amount}_{subject}"
        return f"{sanitize_filename(new_name_raw)}{ext}"

    # 3. ãã®ä»– (è¦ä»¶ 6.3)
    elif category == "ãã®ä»–":
        title = data.get("title", "AIæ¨æ¸¬ã‚¿ã‚¤ãƒˆãƒ«")[:30]
        return f"{sanitize_filename(title)}{ext}"
    
    # äºˆæœŸã›ã¬åˆ†é¡ã‚¨ãƒ©ãƒ¼
    else:
        st.error(f"ğŸš¨ ãƒªãƒãƒ¼ãƒ ãƒ«ãƒ¼ãƒ«é©ç”¨ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ†ã‚´ãƒª '{category}' ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒä¸æ­£ã§ã™ã€‚å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿”ã—ã¾ã™ã€‚")
        return original_name

# ----------------------------------------------------------------------
# 3. Streamlit UIå®šç¾© (è¦ä»¶ 3)
# ----------------------------------------------------------------------

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ğŸ¤– AIã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (Local Mode)", layout="wide")

## ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    st.markdown("""
    **å‹•ä½œãƒ¢ãƒ¼ãƒ‰:** èª°ã§ã‚‚ä½¿ãˆã‚‹ãƒ­ãƒ¼ã‚«ãƒ«ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰
    
    *Gemini APIã‚’ä½¿ç”¨ã—ãªã„ãŸã‚ã€APIã‚­ãƒ¼ã¯ä¸è¦ã§ã™ã€‚*
    *æ–‡æ›¸åˆ†æã«ã¯Pythonã®æ­£è¦è¡¨ç¾ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚*
    *éŸ³å£°æ–‡å­—èµ·ã“ã—ã¯å›ºå®šã®ãƒ¢ãƒƒã‚¯å¿œç­”ã¨ãªã‚Šã¾ã™ã€‚*
    """)
    
    st.markdown("---")
    st.subheader("å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ (è¦ä»¶ 4)")
    st.markdown("""
    * **æ–‡æ›¸**: PDF, DOCX, XLSX, PPTX, CSV
    * **éŸ³å£°**: MP3, WAV, M4A (ãƒ¢ãƒƒã‚¯)
    """)

## ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
st.title("ğŸ¤– AIã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (Local Mode)")
st.caption("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ«ãƒ¼ãƒ«ã§åˆ†æã—ã€è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã‚’è¡Œã„ã¾ã™ã€‚")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ (è¦ä»¶ 3)
uploaded_files = st.file_uploader(
    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (è¤‡æ•°é¸æŠå¯)", 
    type=['pdf', 'docx', 'xlsx', 'pptx', 'csv', 'mp3', 'wav', 'm4a'],
    accept_multiple_files=True
)

if uploaded_files:
    if st.button("ğŸš€ ãƒ­ãƒ¼ã‚«ãƒ«ãƒªãƒãƒ¼ãƒ ãƒ»æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ", use_container_width=True):
        
        # å‡¦ç†çŠ¶æ³ã®è¡¨ç¤º (è¦ä»¶ 3)
        st.subheader("ğŸ“Š å‡¦ç†çµæœ")
        results: List[Dict[str, Any]] = []
        
        progress_bar = st.progress(0)
        
        with st.empty(): 
            for i, uploaded_file in enumerate(uploaded_files):
                
                progress_bar.progress((i + 1) / len(uploaded_files))
                st.info(f"ğŸ‘‰ **{uploaded_file.name}** ã®å‡¦ç†ã‚’é–‹å§‹...")
                
                # 1. ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º/ASRåˆ¤å®š
                text_content, is_asr = extract_text(uploaded_file)
                
                if "å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“" in text_content or "ã‚¨ãƒ©ãƒ¼" in text_content:
                    results.append({
                        "ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                        "å‡¦ç†çŠ¶æ³": "ã‚¹ã‚­ãƒƒãƒ—/ã‚¨ãƒ©ãƒ¼",
                        "åˆ†é¡ã‚«ãƒ†ã‚´ãƒª": "-",
                        "ãƒªãƒãƒ¼ãƒ å¾Œãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                    })
                    continue
                
                # 2. ãƒ­ãƒ¼ã‚«ãƒ«AIã‚³ã‚¢é€£æº
                ai_response = analyze_file_content(text_content, uploaded_file, is_asr)
                
                if ai_response.category == "ä¸æ˜":
                    st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file.name} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç†ç”±: {ai_response.reasoning}")

                # 3. ãƒªãƒãƒ¼ãƒ ãƒ«ãƒ¼ãƒ«é©ç”¨ (è¦ä»¶ 6)
                new_filename = apply_rename_rule(ai_response, uploaded_file.name)
                
                # 4. çµæœã®è¨˜éŒ²ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®è¨­ç½®
                result_data = {
                    "ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                    "å‡¦ç†çŠ¶æ³": "å®Œäº†" if ai_response.category != "ä¸æ˜" else "å¤±æ•—",
                    "åˆ†é¡ã‚«ãƒ†ã‚´ãƒª": ai_response.category,
                    "ãƒªãƒãƒ¼ãƒ å¾Œãƒ•ã‚¡ã‚¤ãƒ«å": new_filename,
                }
                results.append(result_data)
                
                st.markdown(f"**çµæœ ({uploaded_file.name})**:")
                
                col1, col2, col3 = st.columns([1, 1, 2])
                
                with col1:
                    st.download_button(
                        label=f"ğŸ’¾ {new_filename} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=uploaded_file.getvalue(), 
                        file_name=new_filename,
                        mime=uploaded_file.type,
                        key=f"download_renamed_{uploaded_file.name}"
                    )

                if is_asr and ai_response.transcript:
                    with col2:
                        asr_file_name = f"{os.path.splitext(uploaded_file.name)[0]}.txt"
                        st.download_button(
                            label=f"ğŸ“ {asr_file_name} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=ai_response.transcript,
                            file_name=asr_file_name,
                            mime="text/plain",
                            key=f"download_asr_{uploaded_file.name}"
                        )
                
                with col3:
                    st.caption(f"åˆ†é¡: **{ai_response.category}** | ç†ç”±: {ai_response.reasoning}")

            st.success("âœ… å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        st.dataframe(results, use_container_width=True)
        
        st.markdown("---")
        st.subheader("ğŸ’¡ æœ€çµ‚åˆ†æçµæœ (æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿)")
        if 'ai_response' in locals() and ai_response:
            # Pydanticãƒ¢ãƒ‡ãƒ«ã‚’è¾æ›¸ã«å¤‰æ›ã—ã¦è¡¨ç¤º
            st.json(ai_response.model_dump())
        else:
            st.write("ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‡¦ç†ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
